{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T15:41:06.683019Z",
     "start_time": "2024-08-23T15:40:56.921278Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from KeyboardModel import KeyboardModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b493c33db135b75",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence_h5_path = '../../Data/r01/recordings_01_typing_enrollment01_text_typing01.h5'\n",
    "\n",
    "df = pd.read_hdf(sentence_h5_path)\n",
    "df = df[['thumb3', 'thumb4', 'dev_pos', 'keys']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "82ea18a96fa2d87a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T16:11:17.854300Z",
     "start_time": "2024-08-23T16:11:17.847522Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_restored_sentence(df_):\n",
    "    df_tmp = df_.copy()\n",
    "    # restore typed sentence\n",
    "    df_tmp['keys_prev'] = df_tmp['keys'].shift(1).bfill()\n",
    "    pressed_keys_vectors = df_tmp.apply(lambda x: x['keys_prev'] if not np.array_equal(x['keys_prev'], x['keys']) else np.nan, axis=1).dropna() # get rows where pressing state was changed\n",
    "    pressed_keys_indices = pressed_keys_vectors.apply(lambda x: np.argmax(x) if x.sum() > 0 else -1) # extract indices from one-hot vectors (pressing states)\n",
    "    pressed_keys_asciis = pressed_keys_indices.values[np.where(pressed_keys_indices.values >= 0)[0]] + 65 # extract ascii chars\n",
    "    pressed_keys_asciis[np.where(pressed_keys_asciis == 91)[0]] = 32 # fix space ascii char\n",
    "    restored_sentence = ''.join(chr(i) for i in pressed_keys_asciis) # convert array of ascii chars to visible text\n",
    "    restored_sentence = restored_sentence.lower()\n",
    "    \n",
    "    return restored_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce7c27840b570f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T15:41:09.585767Z",
     "start_time": "2024-08-23T15:41:09.579386Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_minmax_values(df_):\n",
    "    df_tmp = df_.copy()\n",
    "\n",
    "    minmax_values = {'thumb3_rel': {'min': [np.inf, np.inf, np.inf], 'max': [-np.inf, -np.inf, -np.inf]},\n",
    "                     'thumb4_rel': {'min': [np.inf, np.inf, np.inf], 'max': [-np.inf, -np.inf, -np.inf]}}\n",
    "\n",
    "    # Get the relative positions\n",
    "    df_tmp['thumb3_rel'] = df_tmp['thumb3'] - df_tmp['dev_pos']\n",
    "    df_tmp['thumb4_rel'] = df_tmp['thumb4'] - df_tmp['dev_pos']\n",
    "\n",
    "    # Create separation between x, y and z values\n",
    "    for pos in range(3):\n",
    "        df_tmp[f'thumb3_rel_{pos}'] = df_tmp['thumb3_rel'].apply(lambda x: x[pos])\n",
    "        df_tmp[f'thumb4_rel_{pos}'] = df_tmp['thumb4_rel'].apply(lambda x: x[pos])\n",
    "\n",
    "    # Calculate the min and max values\n",
    "    for pos in range(3):\n",
    "        minmax_values['thumb3_rel']['min'][pos] = min(minmax_values['thumb3_rel']['min'][pos], min(df_tmp[f'thumb3_rel_{pos}']))\n",
    "        minmax_values['thumb3_rel']['max'][pos] = max(minmax_values['thumb3_rel']['max'][pos], max(df_tmp[f'thumb3_rel_{pos}']))\n",
    "\n",
    "        minmax_values['thumb4_rel']['min'][pos] = min(minmax_values['thumb4_rel']['min'][pos], min(df_tmp[f'thumb4_rel_{pos}']))\n",
    "        minmax_values['thumb4_rel']['max'][pos] = max(minmax_values['thumb4_rel']['max'][pos], max(df_tmp[f'thumb4_rel_{pos}']))\n",
    "\n",
    "    return minmax_values\n",
    "\n",
    "def calculate_avg_distance_diff_for_pressed_seq(df_):\n",
    "    distance_diff_dict = {'thumb3_rel': [], 'thumb4_rel': []}\n",
    "\n",
    "    curr_row = 0\n",
    "    while curr_row < len(df_):\n",
    "        if df_['press'].iloc[curr_row] == 1:\n",
    "            start_point_thumb3_rel = np.array(df_['thumb3_rel'].iloc[curr_row])\n",
    "            start_point_thumb4_rel = np.array(df_['thumb4_rel'].iloc[curr_row])\n",
    "\n",
    "            while curr_row < len(df_) and df_['press'].iloc[curr_row] == 1:\n",
    "                curr_row += 1\n",
    "\n",
    "            end_point_thumb3_rel = np.array(df_['thumb3_rel'].iloc[curr_row - 1])\n",
    "            end_point_thumb4_rel = np.array(df_['thumb4_rel'].iloc[curr_row - 1])\n",
    "\n",
    "            distance_diff_dict['thumb3_rel'].append(np.linalg.norm(end_point_thumb3_rel - start_point_thumb3_rel))\n",
    "            distance_diff_dict['thumb4_rel'].append(np.linalg.norm(end_point_thumb4_rel - start_point_thumb4_rel))\n",
    "\n",
    "        else:\n",
    "            curr_row += 1\n",
    "\n",
    "    distance_diff_dict['thumb3_rel'] = np.mean(distance_diff_dict['thumb3_rel'])\n",
    "    distance_diff_dict['thumb4_rel'] = np.mean(distance_diff_dict['thumb4_rel'])\n",
    "\n",
    "    return distance_diff_dict\n",
    "\n",
    "\n",
    "def is_rows_close(row1, row2, distance_diff_dict, threshold=0.5):\n",
    "    thumb3_diff = np.linalg.norm(np.array(row1['thumb3_rel']) - np.array(row2['thumb3_rel']))\n",
    "    thumb4_diff = np.linalg.norm(np.array(row1['thumb4_rel']) - np.array(row2['thumb4_rel']))\n",
    "\n",
    "    if thumb3_diff < distance_diff_dict['thumb3_rel'] * threshold or thumb4_diff < distance_diff_dict['thumb4_rel'] * threshold:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def create_filtered_df(df_):\n",
    "    avg_diff_dist_for_pressed_seq = calculate_avg_distance_diff_for_pressed_seq(df_)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    curr_row = 0\n",
    "    while curr_row < len(df_):\n",
    "        rows.append(df_.iloc[curr_row])\n",
    "\n",
    "        next_row = curr_row + 1\n",
    "        while next_row < len(df_) and is_rows_close(df_.iloc[curr_row], df_.iloc[next_row],  avg_diff_dist_for_pressed_seq):\n",
    "            next_row += 1\n",
    "\n",
    "        curr_row = next_row\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def normalize_and_filter_df(df_, to_filter=False):\n",
    "    minmax_values = get_minmax_values(df_)\n",
    "\n",
    "    # Get the relative positions\n",
    "    df_['thumb3_rel'] = df_['thumb3'] - df_['dev_pos']\n",
    "    df_['thumb4_rel'] = df_['thumb4'] - df_['dev_pos']\n",
    "\n",
    "    # Normalize the relative positions\n",
    "    df_['thumb3_rel'] = df_['thumb3_rel'].apply(\n",
    "        lambda x: [(x[i] - minmax_values['thumb3_rel']['min'][i]) / (minmax_values['thumb3_rel']['max'][i] - minmax_values['thumb3_rel']['min'][i]) for i in range(3)])\n",
    "\n",
    "    df_['thumb4_rel'] = df_['thumb4_rel'].apply(\n",
    "        lambda x: [(x[i] - minmax_values['thumb4_rel']['min'][i]) / (minmax_values['thumb4_rel']['max'][i] - minmax_values['thumb4_rel']['min'][i]) for i in range(3)])\n",
    "\n",
    "    df_['press'] = df_['keys'].apply(lambda x: 1 if x.any() else 0)\n",
    "\n",
    "    df_['coords'] = df_[['thumb3_rel', 'thumb4_rel']].apply(lambda row: list(row['thumb3_rel']) + list(row['thumb4_rel']), axis=1)\n",
    "\n",
    "    df_ = df_[['coords', 'thumb3_rel', 'thumb4_rel', 'press', 'keys']]\n",
    "    \n",
    "    if to_filter:\n",
    "        df_ = create_filtered_df(df_)\n",
    "\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66fff1081d27fdf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T15:41:10.027460Z",
     "start_time": "2024-08-23T15:41:09.586611Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IN THE PROCESS THEY DEMONSTRATED THET THERE IS STILL A LOT OF LIFE IN HONG KONG CINEMA'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df = normalize_and_filter_df(df)\n",
    "get_restored_sentence(normalized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fe7f40ad151f6a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T15:41:12.222140Z",
     "start_time": "2024-08-23T15:41:10.027170Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IN THEPOCESTHEY DEMONSTRATEDTHET THEE IS TILLALO OF LIFE IN HONGKON INEMA'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = normalize_and_filter_df(df, to_filter=True)\n",
    "get_restored_sentence(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba804a239ab8423f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T15:41:28.028306Z",
     "start_time": "2024-08-23T15:41:12.244072Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "keyboard_model = KeyboardModel(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b9dfa2b09fc3682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T15:41:28.072563Z",
     "start_time": "2024-08-23T15:41:28.032051Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coords</th>\n",
       "      <th>thumb3_rel</th>\n",
       "      <th>thumb4_rel</th>\n",
       "      <th>press</th>\n",
       "      <th>keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.273785481510138, 0.2301122053542864, 0.0311...</td>\n",
       "      <td>[0.273785481510138, 0.2301122053542864, 0.0311...</td>\n",
       "      <td>[0.3615041616703537, 0.1579752358411023, 0.003...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.27412782461549884, 0.22963383239731122, 0.0...</td>\n",
       "      <td>[0.27412782461549884, 0.22963383239731122, 0.0...</td>\n",
       "      <td>[0.36138120817745994, 0.15777145608280213, 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.27463423783243324, 0.22896647409568494, 0.0...</td>\n",
       "      <td>[0.27463423783243324, 0.22896647409568494, 0.0...</td>\n",
       "      <td>[0.3612606622535732, 0.1573589728755944, 0.002...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.274367760849553, 0.22853135414597187, 0.030...</td>\n",
       "      <td>[0.274367760849553, 0.22853135414597187, 0.030...</td>\n",
       "      <td>[0.3617540682712919, 0.15708120207817772, 0.00...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.274645093004048, 0.22795418624399272, 0.029...</td>\n",
       "      <td>[0.274645093004048, 0.22795418624399272, 0.029...</td>\n",
       "      <td>[0.36194800535651106, 0.1561074795908664, 0.00...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              coords  \\\n",
       "0  [0.273785481510138, 0.2301122053542864, 0.0311...   \n",
       "1  [0.27412782461549884, 0.22963383239731122, 0.0...   \n",
       "2  [0.27463423783243324, 0.22896647409568494, 0.0...   \n",
       "3  [0.274367760849553, 0.22853135414597187, 0.030...   \n",
       "4  [0.274645093004048, 0.22795418624399272, 0.029...   \n",
       "\n",
       "                                          thumb3_rel  \\\n",
       "0  [0.273785481510138, 0.2301122053542864, 0.0311...   \n",
       "1  [0.27412782461549884, 0.22963383239731122, 0.0...   \n",
       "2  [0.27463423783243324, 0.22896647409568494, 0.0...   \n",
       "3  [0.274367760849553, 0.22853135414597187, 0.030...   \n",
       "4  [0.274645093004048, 0.22795418624399272, 0.029...   \n",
       "\n",
       "                                          thumb4_rel  press  \\\n",
       "0  [0.3615041616703537, 0.1579752358411023, 0.003...      0   \n",
       "1  [0.36138120817745994, 0.15777145608280213, 0.0...      0   \n",
       "2  [0.3612606622535732, 0.1573589728755944, 0.002...      0   \n",
       "3  [0.3617540682712919, 0.15708120207817772, 0.00...      0   \n",
       "4  [0.36194800535651106, 0.1561074795908664, 0.00...      0   \n",
       "\n",
       "                                                keys  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98a24de1a4a31e91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T15:41:28.084241Z",
     "start_time": "2024-08-23T15:41:28.078318Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_number_of_typing_press(keyboard_model_: KeyboardModel, df_: pd.DataFrame, device_, prefix_percentage=0.5):\n",
    "    total_number_of_presses_pred = 0\n",
    "    total_number_of_presses_gt = 0\n",
    "    \n",
    "    seq_len = keyboard_model_.typing_seq_len\n",
    "    \n",
    "    curr_position = int(len(df_) * prefix_percentage)\n",
    "    end_position = len(df_)\n",
    "    \n",
    "    while curr_position < end_position - seq_len:\n",
    "        # Gather the input data\n",
    "        input_data = df_.iloc[curr_position - seq_len:curr_position]['coords'].tolist()\n",
    "        input_data = torch.tensor(input_data)\n",
    "        input_data = input_data.type(torch.float32).to(device_)\n",
    "        \n",
    "        # Predict the next key\n",
    "        outputs = keyboard_model_.typing_model(input_data)\n",
    "        next_probability = outputs.squeeze(-1)[-1].detach().cpu()\n",
    "        next_prediction = (torch.sigmoid(next_probability) > 0.5).item()\n",
    "        \n",
    "        if next_prediction:\n",
    "            total_number_of_presses_pred += 1\n",
    "            \n",
    "        total_number_of_presses_gt += df_.iloc[curr_position]['press']\n",
    "        \n",
    "        curr_position += 1\n",
    "    \n",
    "    return {'pred': total_number_of_presses_pred, 'gt': total_number_of_presses_gt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fb21d09e7c9a4a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T15:53:41.495512Z",
     "start_time": "2024-08-23T15:53:41.438167Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_number_of_new_chars(keyboard_model_: KeyboardModel, df_: pd.DataFrame, device_, prefix_percentage=0.5):\n",
    "    results_typing_press = predict_number_of_typing_press(keyboard_model_, df_, device_, prefix_percentage)\n",
    "    typing_press_pred = results_typing_press['pred']\n",
    "    typing_press_gt = results_typing_press['gt']\n",
    "    \n",
    "    # calculate ratio of typing presses / characters\n",
    "    ratio = typing_press_gt / len(get_restored_sentence(df_))\n",
    "    \n",
    "    return {'typing_press_pd': typing_press_pred, 'typing_press_gt': typing_press_gt, 'ratio': ratio,\n",
    "            'new_chars_pred': int(typing_press_pred / ratio), 'new_chars_gt': int(typing_press_gt / ratio)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8174ca4e2620a6f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T15:53:42.927817Z",
     "start_time": "2024-08-23T15:53:42.916291Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_tokenization_dict():\n",
    "    char_to_idx = {'pad':0, 'eos': 1}\n",
    "    for i in range(0, 255):\n",
    "        char_to_idx[chr(i)] = i + 2\n",
    "        \n",
    "    idx_to_char = {v: k for k, v in char_to_idx.items()}\n",
    "    \n",
    "    return char_to_idx, idx_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8878e258b4e9df61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T15:53:44.047031Z",
     "start_time": "2024-08-23T15:53:44.035424Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_sentence(sentence, char_to_idx):\n",
    "    return torch.tensor([char_to_idx[char] for char in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3c8bcb656008d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T16:16:04.933627Z",
     "start_time": "2024-08-23T16:16:04.918956Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def restore_sentence(keyboard_model_: KeyboardModel, df_: pd.DataFrame, device_, to_concat_gt = False, prefix_percentage=0.5):\n",
    "    sentence_prefix = get_restored_sentence(df_.iloc[:int(len(df_) * prefix_percentage)])\n",
    "    restored_sentence = sentence_prefix\n",
    "\n",
    "    sentence_all = get_restored_sentence(df_)\n",
    "    curr_sentence_idx = len(sentence_prefix)\n",
    "\n",
    "    char_to_idx, idx_to_char = get_tokenization_dict()\n",
    "    sentence_prefix_tokenized = tokenize_sentence(sentence_prefix, char_to_idx)\n",
    "\n",
    "    input_ids = sentence_prefix_tokenized.view(-1, 1).to(device_)\n",
    "    results_num_new_chars = predict_number_of_new_chars(keyboard_model_, df_, device_, prefix_percentage)\n",
    "\n",
    "    for i in range(results_num_new_chars['new_chars_gt']):\n",
    "        outputs = keyboard_model_.char_model(input_ids)['logits']\n",
    "        \n",
    "        _, predicted = torch.max(outputs, -1)\n",
    "        predicted = predicted.view(-1)[-1]\n",
    "        \n",
    "        restored_sentence += idx_to_char[predicted.item()]\n",
    "        \n",
    "        if to_concat_gt and curr_sentence_idx < len(sentence_all):\n",
    "            next_char = char_to_idx[sentence_all[curr_sentence_idx]]\n",
    "            next_char = torch.tensor([next_char]).view(-1, 1).to(device_)\n",
    "            \n",
    "        else:\n",
    "            next_char = predicted.view(-1, 1).to(device_)\n",
    "            \n",
    "        input_ids = torch.cat((input_ids, next_char), dim=0)\n",
    "        \n",
    "        curr_sentence_idx += 1\n",
    "        \n",
    "    return {\n",
    "        'sentence_prefix': sentence_prefix,\n",
    "        'restored_sentence': restored_sentence,\n",
    "        'sentence_all': sentence_all,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9788a4f137ea51d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T16:25:06.754494Z",
     "start_time": "2024-08-23T16:25:06.743151Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_recording_files(data_dir):\n",
    "    recordings = {}\n",
    "    for folder_name in os.listdir(data_dir):\n",
    "        if folder_name.startswith('r'):\n",
    "            for file_name in os.listdir(f'{data_dir}/{folder_name}'):\n",
    "                if file_name.endswith('.h5'):\n",
    "                    if folder_name not in recordings:\n",
    "                        recordings[folder_name] = []\n",
    "                    recordings[folder_name].append(f'{data_dir}/{folder_name}/{file_name}')\n",
    "\n",
    "    return recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9b75d0dd8b65c296",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T16:25:13.705785Z",
     "start_time": "2024-08-23T16:25:13.541761Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r24': ['../../Data/r24/recordings_24_typing_enrollment03_text_typing03.h5',\n",
       "  '../../Data/r24/recordings_24_typing_enrollment02_text_typing02.h5',\n",
       "  '../../Data/r24/recordings_24_typing_enrollment01_text_typing01.h5'],\n",
       " 'r01': ['../../Data/r01/recordings_01_typing_enrollment01_text_typing01.h5',\n",
       "  '../../Data/r01/recordings_01_typing_enrollment02_text_typing02.h5',\n",
       "  '../../Data/r01/recordings_01_typing_enrollment03_text_typing03.h5'],\n",
       " 'r23': ['../../Data/r23/recordings_23_typing_enrollment03_text_typing03.h5',\n",
       "  '../../Data/r23/recordings_23_typing_enrollment02_text_typing02.h5',\n",
       "  '../../Data/r23/recordings_23_typing_enrollment01_text_typing01.h5'],\n",
       " 'r04': ['../../Data/r04/recordings_04_typing_enrollment03_text_typing03.h5',\n",
       "  '../../Data/r04/recordings_04_typing_enrollment02_text_typing02.h5',\n",
       "  '../../Data/r04/recordings_04_typing_enrollment01_text_typing01.h5'],\n",
       " 'r25': ['../../Data/r25/recordings_25_typing_enrollment03_text_typing04.h5',\n",
       "  '../../Data/r25/recordings_25_typing_enrollment03_text_typing03.h5',\n",
       "  '../../Data/r25/recordings_25_typing_enrollment01_text_typing01.h5',\n",
       "  '../../Data/r25/recordings_25_typing_enrollment02_text_typing02.h5'],\n",
       " 'r06': ['../../Data/r06/recordings_06_typing_enrollment01_text_typing01.h5',\n",
       "  '../../Data/r06/recordings_06_typing_enrollment02_text_typing02.h5',\n",
       "  '../../Data/r06/recordings_06_typing_enrollment03_text_typing03.h5'],\n",
       " 'r17': ['../../Data/r17/recordings_17_typing_enrollment02_text_typing02.h5',\n",
       "  '../../Data/r17/recordings_17_typing_enrollment01_text_typing01.h5',\n",
       "  '../../Data/r17/recordings_17_typing_enrollment03_text_typing03.h5',\n",
       "  '../../Data/r17/recordings_17_typing_enrollment03_text_typing04.h5'],\n",
       " 'r20': ['../../Data/r20/recordings_20_typing_enrollment02_text_typing02.h5',\n",
       "  '../../Data/r20/recordings_20_typing_enrollment01_text_typing01.h5',\n",
       "  '../../Data/r20/recordings_20_typing_enrollment03_text_typing03.h5'],\n",
       " 'r05': ['../../Data/r05/recordings_05_typing_enrollment03_text_typing04.h5',\n",
       "  '../../Data/r05/recordings_05_typing_enrollment03_text_typing03.h5',\n",
       "  '../../Data/r05/recordings_05_typing_enrollment01_text_typing01.h5',\n",
       "  '../../Data/r05/recordings_05_typing_enrollment02_text_typing02.h5'],\n",
       " 'r19': ['../../Data/r19/recordings_19_typing_enrollment01_text_typing01.h5',\n",
       "  '../../Data/r19/recordings_19_typing_enrollment02_text_typing02.h5',\n",
       "  '../../Data/r19/recordings_19_typing_enrollment03_text_typing03.h5'],\n",
       " 'r10': ['../../Data/r10/recordings_10_typing_enrollment02_text_typing02.h5',\n",
       "  '../../Data/r10/recordings_10_typing_enrollment01_text_typing01.h5',\n",
       "  '../../Data/r10/recordings_10_typing_enrollment03_text_typing03.h5'],\n",
       " 'r21': ['../../Data/r21/recordings_21_typing_enrollment01_text_typing01.h5',\n",
       "  '../../Data/r21/recordings_21_typing_enrollment02_text_typing02.h5',\n",
       "  '../../Data/r21/recordings_21_typing_enrollment03_text_typing03.h5',\n",
       "  '../../Data/r21/recordings_21_typing_enrollment03_text_typing04.h5']}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_recording_files('../../Data')"
   ]
  },
  {
   "cell_type": "code",
   "id": "1dd88f3fcacb3959",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
